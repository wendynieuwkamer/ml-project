{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# These are the paths to the data. These differ per user. \n",
    "test = pd.read_csv('/Users/imac/Documents/Tijdelijk/Machine Learning/EindProject/ml-project/data/test.csv', \n",
    "                   delimiter=',')\n",
    "train = pd.read_csv('/Users/imac/Documents/Tijdelijk/Machine Learning/EindProject/ml-project/data/train.csv', \n",
    "                    delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is to prepare the data to be optimized. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode(train, test):\n",
    "    le = LabelEncoder().fit(train.species) \n",
    "    labels = le.transform(train.species)           \n",
    "    classes = list(le.classes_)                    \n",
    "    test_ids = test.id                             \n",
    "    \n",
    "    train = train.drop(['species', 'id'], axis=1)  \n",
    "    test = test.drop(['id'], axis=1)\n",
    "    \n",
    "    return train, labels, test, test_ids, classes\n",
    "\n",
    "train, labels, test, test_ids, classes = encode(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit(test_size=0.2, random_state=23)\n",
    "sss.get_n_splits(train.values, labels)\n",
    "\n",
    "for train_index, test_index in sss.split(train.values, labels):\n",
    "    X_train, X_test = train.values[train_index], train.values[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is the actual gridseach on the parameters for KNeighbors, DecisionTrees and AdaBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#These are the parameters we are going to optimize using gridseach.\n",
    "parameters_KN = [{'n_neighbors':range(1, 10), 'weights':['uniform', 'distance']}]\n",
    "parameters_DT = [{'criterion':['gini', 'entropy'], 'splitter':['best', 'random'], 'min_samples_leaf':[1, 2]}]\n",
    "parameters_AB = [{'n_estimators':range(25,75), 'learning_rate':[0.7,0.8,0.9,1.0,1.1,1.2,1.3,1.4,1.5]}]\n",
    "parameters_AB_low = [{'n_estimators':range(25,75), 'learning_rate':[0.1,0.2,0.3,0.4,0.5,0.6,0.7]}] \n",
    "parameters_AB_lower = [{'n_estimators':range(25,75), 'learning_rate':[0.01,0.02,0.03,0.04,0.05,0.06,0.07, 0.08, 0.09]}] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Possible Improvements\n",
    "parameters_KN = [{'n_neighbors':range(1, 10), 'weights':['uniform', 'distance']}]\n",
    "parameters_DT = [{'criterion':['gini', 'entropy'], 'splitter':['best', 'random'], 'min_samples_leaf':[1, 2]}]\n",
    "parameters_AB = [{'n_estimators':range(25,75), 'learning_rate':[0.1,0.2,0.3,0.4,0.5,0.6,0.7]}] \n",
    "# By previously running [0.7,0.8,0.9,1.0,1.1,1.2,1.3,1.4,1.5], 0.7 was the best so we will try to decrease this even \n",
    "# further to see if that improves the accuracy even further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "Best parameters set found on development set: \n",
      "\n",
      "{'n_neighbors': 1, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "# KNEIGHBORS\n",
    "print(\"# Tuning hyper-parameters for accuracy\")\n",
    "    \n",
    "clf = GridSearchCV(KNeighborsClassifier(n_neighbors=3, weights='uniform', n_jobs=-1), parameters_KN, cv=5,\n",
    "                   scoring='accuracy')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set: \\n\")\n",
    "print(clf.best_params_)\n",
    "\n",
    "Grid_scores_KN = []\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    Grid_scores_KN.append(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "Best parameters set found on development set: \n",
      "\n",
      "{'splitter': 'best', 'criterion': 'gini', 'min_samples_leaf': 1}\n"
     ]
    }
   ],
   "source": [
    "# DECISION TREE\n",
    "print(\"# Tuning hyper-parameters for accuracy\")\n",
    "\n",
    "clf = GridSearchCV(DecisionTreeClassifier(criterion='gini', splitter='best', min_samples_leaf=1), \n",
    "                      parameters_DT, cv=5, scoring='accuracy')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set: \\n\")\n",
    "print(clf.best_params_)\n",
    "\n",
    "Grid_scores_DT = []\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    Grid_scores_DT.append(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "Best parameters set found on development set: \n",
      "\n",
      "{'n_estimators': 67, 'learning_rate': 0.7}\n"
     ]
    }
   ],
   "source": [
    "# ADABOOST\n",
    "print(\"# Tuning hyper-parameters for accuracy\")\n",
    "\n",
    "clf = GridSearchCV(AdaBoostClassifier(n_estimators=50, learning_rate=1.0), parameters_AB, \n",
    "                   cv=5, scoring='accuracy')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set: \\n\")\n",
    "print(clf.best_params_)\n",
    "\n",
    "Grid_scores_AB = []\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    Grid_scores_AB.append(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "Best parameters set found on development set: \n",
      "\n",
      "{'n_estimators': 70, 'learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# ADABOOST LOW\n",
    "print(\"# Tuning hyper-parameters for accuracy\")\n",
    "\n",
    "clf = GridSearchCV(AdaBoostClassifier(n_estimators=50, learning_rate=1.0), parameters_AB_low, \n",
    "                   cv=5, scoring='accuracy')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set: \\n\")\n",
    "print(clf.best_params_)\n",
    "\n",
    "Grid_scores_AB_low = []\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    Grid_scores_AB_low.append(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "Best parameters set found on development set: \n",
      "\n",
      "{'n_estimators': 72, 'learning_rate': 0.03}\n"
     ]
    }
   ],
   "source": [
    "# ADABOOST LOWER\n",
    "print(\"# Tuning hyper-parameters for accuracy\")\n",
    "\n",
    "clf = GridSearchCV(AdaBoostClassifier(n_estimators=50, learning_rate=1.0), parameters_AB_lower, \n",
    "                   cv=5, scoring='accuracy')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set: \\n\")\n",
    "print(clf.best_params_)\n",
    "\n",
    "Grid_scores_AB_lower = []\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    Grid_scores_AB_lower.append(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
